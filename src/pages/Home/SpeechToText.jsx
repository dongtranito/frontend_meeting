import React, { useState, useRef } from "react";
import * as sdk from "microsoft-cognitiveservices-speech-sdk";
import BoardScript from "./BoardScript";
import { formatMilliseconds } from "../../utils/time";
import { useTimer } from "../../hooks/useTimer";
import SpeechControls from "./SpeechControls";



const SpeechToText = ({ onTranscriptProcessed }) => {
    const [status, setStatus] = useState("idle"); // "idle" | "recording" | "paused"
    const [currentText, setCurrentText] = useState("");
    const transcriberRef = useRef(null);
    const transcriptRef = useRef([]);
    const [speakerMap, setSpeakerMap] = useState({});
    const speakerMapRef = useRef({});
    console.log("hi")
    const {
        elapsedTime,
        elapsedTimeRef,
        start: startTimer,
        pause: pauseTimer,
        reset: resetTimer
    } = useTimer();


    const updateSpeakerName = (oldName, newName) => {
        const newMap = { ...speakerMap, [oldName]: newName };
        transcriptRef.current = transcriptRef.current.map(line =>
            line.speaker === oldName ? { ...line, speaker: newName } : line
        );
        setSpeakerMap(newMap);
        speakerMapRef.current = newMap;
    };




    const startRecognition = async () => {
        setStatus("recording");
        setCurrentText("üé§ ƒêang nghe...");
        transcriptRef.current = [];

        startTimer();
        try {
            const res = await fetch("http://localhost:3001/api/token");
            const { token, region } = await res.json();

            const speechConfig = sdk.SpeechConfig.fromAuthorizationToken(token, region);
            speechConfig.speechRecognitionLanguage = "vi-VN";

            speechConfig.setProperty(
                sdk.PropertyId.SpeechServiceConnection_EnableSpeakerDiarization,
                "true"
            );
            speechConfig.setProperty(
                sdk.PropertyId.SpeechServiceResponse_DiarizeSpeakerSegments,
                "true"
            );

            let audioConfig;
            try {
                audioConfig = sdk.AudioConfig.fromDefaultMicrophoneInput();
            } catch (err) {
                console.error("Kh√¥ng th·ªÉ l·∫•y mic:", err);
                setCurrentText("‚ùå Kh√¥ng th·ªÉ truy c·∫≠p micro");
                setStatus("idle");
                return;
            }
            const transcriber = new sdk.ConversationTranscriber(speechConfig, audioConfig);
            transcriberRef.current = transcriber;

            transcriber.transcribing = (s, e) => {
                setCurrentText(e.result.text);
            };

            transcriber.transcribed = (s, e) => {
                if (e.result.reason === sdk.ResultReason.RecognizedSpeech) {

                    const parsed = JSON.parse(e.result.json);
                    const id = parsed.Id;
                    const displayText = parsed.DisplayText || "";
                    const speakerId = parsed.SpeakerId || "Kh√¥ng r√µ ng∆∞·ªùi n√≥i";
                    if (
                        speakerId.toLowerCase() === "unknown" ||
                        displayText.trim().split(/\s+/).length < 5
                    ) {
                        return; // b·ªè qua v√≤ng l·∫∑p
                    }
                    const speaker = speakerMapRef.current[speakerId] || speakerId;


                    const durationInMs = parsed.Duration / 10000; // Azure tr·∫£ v·ªÅ ƒë∆°n v·ªã 100-nanoseconds => chia 10,000 ƒë·ªÉ ra milliseconds
                    const speechStartTime = elapsedTimeRef.current - durationInMs;
                    let time = formatMilliseconds(speechStartTime);

                    transcriptRef.current.push({ speaker, text: displayText, time: time });
                    setCurrentText("");
                }
            };

            transcriber.canceled = (s, e) => {
                console.error("Canceled Event", e);
                const errorMsg = e.errorDetails || "Kh√¥ng r√µ l·ªói";
                setCurrentText(`‚õî Nh·∫≠n di·ªán b·ªã h·ªßy: ${errorMsg}`);
                setStatus("idle");
                resetTimer();
            };

            transcriber.startTranscribingAsync(
                () => console.log("üéôÔ∏è B·∫Øt ƒë·∫ßu transcribe..."),
                err => {
                    console.error("L·ªói startTranscribingAsync:", err);
                    setCurrentText("‚ùå Kh√¥ng th·ªÉ b·∫Øt ƒë·∫ßu nh·∫≠n di·ªán.");
                    setStatus("idle");
                    resetTimer()
                }
            );
        } catch (err) {
            console.error("Speech error:", err);
            setCurrentText("‚ùå L·ªói khi nh·∫≠n di·ªán.");
            setStatus("idle");
            resetTimer();
        }
    };

    const pauseRecognition = () => {
        if (transcriberRef.current) {
            transcriberRef.current.stopTranscribingAsync(
                () => {
                    setStatus("paused");
                    setCurrentText("‚è∏Ô∏è ƒê√£ t·∫°m d·ª´ng");
                    pauseTimer();
                },
                err => console.error("L·ªói khi t·∫°m d·ª´ng:", err)
            );
        }
    };

    const resumeRecognition = () => {
        if (transcriberRef.current) {
            transcriberRef.current.startTranscribingAsync(
                () => {
                    setStatus("recording");
                    setCurrentText("‚ñ∂Ô∏è ƒêang ti·∫øp t·ª•c...");
                    startTimer();

                },
                err => {
                    console.error("L·ªói khi ti·∫øp t·ª•c:", err);
                    setCurrentText("‚ùå Kh√¥ng th·ªÉ ti·∫øp t·ª•c.");
                    resetTimer();
                }
            );
        }
    };

    const stopRecognition = () => {
        if (transcriberRef.current) {
            transcriberRef.current.stopTranscribingAsync(
                () => {
                    transcriberRef.current = null;
                    setStatus("idle");
                    setCurrentText("‚èπÔ∏è ƒê√£ d·ª´ng ho√†n to√†n");
                    resetTimer();

                    // ‚ùå Kh√¥ng g·ª≠i v·ªÅ backend ·ªü ƒë√¢y n·ªØa
                },
                err => console.error("L·ªói khi d·ª´ng:", err)
            );
        }
    };


    const handleSubmitTranscript = () => {
        if (transcriptRef.current.length === 0) {
            alert("Ch∆∞a c√≥ n·ªôi dung ƒë·ªÉ g·ª≠i.");
            return;
        }

        fetch("http://localhost:3001/api/submitTranscript", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ transcript: transcriptRef.current })
        })
            .then(res => {
                if (!res.ok) throw new Error("HTTP error " + res.status);
                return res.json();
            })
            .then(data => {
                console.log("Backend response:", data);
                onTranscriptProcessed(data);

                alert("‚úÖ G·ª≠i bi√™n b·∫£n th√†nh c√¥ng!");
                // N·∫øu mu·ªën xo√° transcript sau khi g·ª≠i:
                // transcriptRef.current = [];
            })
            .catch(err => {
                console.error("G·ª≠i v·ªÅ backend l·ªói:", err);
                alert("‚ùå G·ª≠i th·∫•t b·∫°i.");
            });
    };


    return (
        <div className="w-full mx-auto py-4 px-6 bg-white rounded text-center relative h-full">

            {status === "idle" && transcriptRef.current.length > 0 && (
                <button
                    onClick={handleSubmitTranscript}
                    className="absolute bottom-4 right-10 px-4 py-1 bg-blue-600 hover:bg-blue-700 text-white rounded shadow"
                >
                    üìÑ T·∫°o bi√™n b·∫£n
                </button>)}

            <SpeechControls
                status={status}
                onStart={startRecognition}
                onPause={pauseRecognition}
                onResume={resumeRecognition}
                onStop={stopRecognition}
                time={formatMilliseconds(elapsedTimeRef.current)}
            />
            <BoardScript
                scripts={transcriptRef.current}
                currentText={currentText}
                onRenameSpeaker={updateSpeakerName}
            />

        </div>
    );
};

export default SpeechToText;
