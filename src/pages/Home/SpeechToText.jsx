import React, { useState, useEffect, useRef } from "react";
import * as sdk from "microsoft-cognitiveservices-speech-sdk";
import BoardScript from "./BoardScript";
import { formatMilliseconds } from "../../utils/time";
import { useTimer } from "../../hooks/useTimer";
import SpeechControls from "./SpeechControls";
import Chat from "./Chat";
import { fetchWithAuth } from "../../utils/fetchWithAuth";

const SpeechToText = ({ onTranscriptProcessed }) => {
    const [status, setStatus] = useState("idle"); // "idle" | "recording" | "paused"
    const [currentText, setCurrentText] = useState("");
    const [transcript, setTranscript] = useState([]);
    const [speakerMap, setSpeakerMap] = useState({});
    const [summaryData, setSummaryData] = useState(null);
    const [bienbanData, setBienbanData] = useState("ch∆∞a c√≥ bi√™n b·∫£n c≈©");
    const [thoiGianNop, setThoiGianNop] = useState(null);

    const transcriberRef = useRef(null);
    const speakerMapRef = useRef({});
    const {
        elapsedTime,
        elapsedTimeRef,
        start: startTimer,
        pause: pauseTimer,
        reset: resetTimer,
    } = useTimer();

    // Load transcript t·ª´ localStorage khi v√†o trang
    useEffect(() => {
        const transcriptRaw = localStorage.getItem("transcriptRaw");
        if (transcriptRaw) {
            const parsed = JSON.parse(transcriptRaw);
            setTranscript(parsed.transcript);
            setThoiGianNop(parsed.thoiGianKetThuc);
            setBienbanData(parsed.bienBanData);
            setSummaryData(parsed.summaryData);

            onTranscriptProcessed({transcriptRaw:parsed,   
                summaryData:parsed.summaryData,
                bienBanData:parsed.bienBanData,
            });
        }
    }, []);


    const updateSpeakerName = (oldName, newName) => {
        const newMap = { ...speakerMap, [oldName]: newName };
        const updatedTranscript = transcript.map((line) =>
            line.speaker === oldName ? { ...line, speaker: newName } : line
        );
        setTranscript(updatedTranscript);
        setSpeakerMap(newMap);
        speakerMapRef.current = newMap;
    };

    const startRecognition = async () => {
        setStatus("recording");
        setCurrentText("üé§ ƒêang nghe...");
        setTranscript([]);
        startTimer();
        localStorage.removeItem("transcriptRaw");
        try {
            const res = await fetchWithAuth("http://localhost:3001/api/token",
                {
                    credentials: "include", 
                }
            );
            const { token, region } = await res.json();

            const speechConfig = sdk.SpeechConfig.fromAuthorizationToken(token, region);
            speechConfig.speechRecognitionLanguage = "vi-VN";

            speechConfig.setProperty(
                sdk.PropertyId.SpeechServiceConnection_EnableSpeakerDiarization,
                "true"
            );
            speechConfig.setProperty(
                sdk.PropertyId.SpeechServiceResponse_DiarizeSpeakerSegments,
                "true"
            );

            const audioConfig = sdk.AudioConfig.fromDefaultMicrophoneInput();
            const transcriber = new sdk.ConversationTranscriber(speechConfig, audioConfig);
            transcriberRef.current = transcriber;

            transcriber.transcribing = (s, e) => {
                setCurrentText(e.result.text);
            };

            transcriber.transcribed = (s, e) => {
                if (e.result.reason === sdk.ResultReason.RecognizedSpeech) {
                    const parsed = JSON.parse(e.result.json);
                    const speakerId = parsed.SpeakerId || "Kh√¥ng r√µ ng∆∞·ªùi n√≥i";
                    const displayText = parsed.DisplayText || "";

                    if (
                        speakerId.toLowerCase() === "unknown" ||
                        displayText.trim().split(/\s+/).length < 5
                    ) return;

                    const speaker = speakerMapRef.current[speakerId] || speakerId;
                    const durationInMs = parsed.Duration / 10000;
                    const speechStartTime = elapsedTimeRef.current - durationInMs;
                    const time = formatMilliseconds(speechStartTime);

                    setTranscript((prev) => [
                        ...prev,
                        { speaker, text: displayText, time },
                    ]);
                    setCurrentText("");
                }
            };

            transcriber.canceled = (s, e) => {
                console.error("Canceled", e.errorDetails);
                setCurrentText("‚õî Nh·∫≠n di·ªán b·ªã h·ªßy");
                setStatus("idle");
                resetTimer();
            };

            transcriber.startTranscribingAsync(
                () => console.log("üéôÔ∏è B·∫Øt ƒë·∫ßu transcribe..."),
                (err) => {
                    console.error("L·ªói transcribe:", err);
                    setCurrentText("‚ùå Kh√¥ng th·ªÉ b·∫Øt ƒë·∫ßu nh·∫≠n di·ªán");
                    setStatus("idle");
                    resetTimer();
                }
            );
        } catch (err) {
            console.error("Speech error:", err);
            setCurrentText("‚ùå L·ªói khi nh·∫≠n di·ªán");
            setStatus("idle");
            resetTimer();
        }
    };

    const pauseRecognition = () => {
        transcriberRef.current?.stopTranscribingAsync(
            () => {
                setStatus("paused");
                setCurrentText("‚è∏Ô∏è ƒê√£ t·∫°m d·ª´ng");
                pauseTimer();
            },
            (err) => console.error("L·ªói pause:", err)
        );
    };

    const resumeRecognition = () => {
        transcriberRef.current?.startTranscribingAsync(
            () => {
                setStatus("recording");
                setCurrentText("‚ñ∂Ô∏è ƒêang ti·∫øp t·ª•c...");
                startTimer();
            },
            (err) => {
                console.error("L·ªói resume:", err);
                setCurrentText("‚ùå Kh√¥ng th·ªÉ ti·∫øp t·ª•c.");
                resetTimer();
            }
        );
    };

    const stopRecognition = () => {
        transcriberRef.current?.stopTranscribingAsync(
            () => {
                transcriberRef.current = null;
                const thoiGian = new Date().toLocaleString("vi-VN"); // ‚úÖ l·∫•y tr∆∞·ªõc
                setThoiGianNop(thoiGian);
                setStatus("idle");
                setCurrentText("‚èπÔ∏è ƒê√£ d·ª´ng ho√†n to√†n");
                resetTimer();
                localStorage.setItem("transcriptRaw", JSON.stringify({
                    transcript,
                    thoiGianKetThuc: thoiGianNop,
                }));
            },
            (err) => console.error("L·ªói stop:", err)
        );
    };


    // ·ªü h√†m n√†y th√¨ m√¨nh c√≥ th·ªÉ g·∫Øn bi·∫øn tr·∫°ng th√°i ƒë√£ g·ªüi, ho·∫∑c ƒë√£ g·ªüi xong, xong r√¥i r·ªìi truy·ªÅn xu·ªëng component con c≈©ng ƒë∆∞·ª£c, m√† m√¨nh l·ª° l√†m ·ªü component con r·ªìi th√¨ th√¥i
    const handleSubmitTranscript = (transcriptChat) => {
        if (transcript.length === 0) {
            alert("Ch∆∞a c√≥ n·ªôi dung ƒë·ªÉ g·ª≠i.");
            return;
        }

        return fetchWithAuth("http://localhost:3001/api/submitTranscript", {  // c√°i n√†y l√† m√¨nh return v·ªÅ m·ªôt promise, n·∫øu mu·ªën d·ªÖ nh√¨n th√¨ vi·∫øt b·∫±ng async 
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
                transcript,
                transcriptChat,
                thoiGianKetThuc: thoiGianNop,
                bienBanData: bienbanData,
                summaryData: summaryData,
            }),
            credentials: "include"
        })
            .then((res) => {
                if (!res.ok) throw new Error("HTTP error " + res.status);
                return res.json();
            })
            .then((data) => {
                onTranscriptProcessed(data);
                setBienbanData(data.bienBanData);
                setSummaryData(data.summaryData);
                // C·∫≠p nh·∫≠t d·ªØ li·ªáu v√†o localStorage (khi nh·∫≠n ƒë∆∞·ª£c sumaryData)
                localStorage.setItem("transcriptRaw", JSON.stringify({
                    transcript,
                    thoiGianKetThuc: thoiGianNop,
                    bienBanData: data.bienBanData,
                    summaryData: data.summaryData,
                }));
            })
            .catch((err) => {
                console.error("L·ªói g·ª≠i:", err);
            });
    };

    return (
        <div className="w-full mx-auto py-4 px-6 bg-white rounded text-center relative h-full">
            {status === "idle" && transcript.length > 0 && (
                <div className="absolute bottom-4 w-full left-0">
                    <Chat onClick={handleSubmitTranscript} />
                </div>
            )}

            <SpeechControls
                status={status}
                onStart={startRecognition}
                onPause={pauseRecognition}
                onResume={resumeRecognition}
                onStop={stopRecognition}
                time={formatMilliseconds(elapsedTimeRef.current)}
            />

            <BoardScript
                scripts={transcript}
                currentText={currentText}
                onRenameSpeaker={updateSpeakerName}
            />
        </div>
    );
};

export default SpeechToText;
